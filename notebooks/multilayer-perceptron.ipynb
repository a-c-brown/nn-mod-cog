{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Understand the principles behind the creation of the multilayer perceptron\n",
    "2. Identify how the multilayer perceptron overcame many of the limitations of previous models\n",
    "3. Expand understanding of learning via gradient descent methods\n",
    "4. Develop a basic code implementation of the multilayer perceptron in Python\n",
    "5. Determine what kind of problems can and can't be solved with the multilayer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical and theoretical background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The origin of the backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks research came close to become an anecdote in the history of cognitive science by 1980. The vast majority of researchers in cognitive science and artificial intelligence thought that neural nets were a silly idea, they could not possibly work. Minsky and Papert even provided formal proofs about it 1969. Yet, as any person that has been around science long enough knows, there are plenty of stubborn researchers that will continue paddling against the current in pursue of their own ideas. \n",
    "\n",
    "David Rumelhart first heard about perceptrons and neural nets in 1963 while in graduate school at Stanford. At the time, he was doing research in mathematical psychology, which although it has lots of equations, is a different field, so he did not pay too much attention to neural nets. It wasn't until the early 70's that Rumelhart took neural nets more seriously. He was in pursuit of a more general framework to understand cognition. Mathematical psychology looked too much like a disconnected mosaic of ad-doc formulas for him. By the late '70s, Rumelhart was working at UC San Diego. He and some colleagues formed a study group about neural networks in cognitive science, that eventually evolved into what is known as the \"Parallel Distributed Processing\" (PDP) research group. Among the members of that group were Geoffrey Hinton, Terrence Sejnowski, Michael I. Jordan, Jeffrey L. Elman, Francis Crick, and others that eventually became prominent researchers in the neural networks and artificial intelligence fields. \n",
    "\n",
    "The original intention of the PDP group was to create a compendium of the most important research on neural networks. Their enterprise eventually evolved into something larger, producing the famous two volumes book where the so-called \"backpropagation\" algorithm was introduced, along with other important models and ideas. Although most people today associate the invention of the gradient descent algorithm with Hinton, the person that came up the idea was David Rumelhart, and as in most things in science, it was just a small change to a previous idea. Rumelhart and James McClelland (another young professor at UC San Diego) wanted to train a neural network with multiple layers and sigmoidal units, instead of threshold units (as in the perceptron) or linear units (as in the ADALINE), but they did not how to train such a model. Rumelhart knew that you could use gradient descent to train networks with linear units, as Widrow and Hoff did, so he thought that he might as well pretend that sigmoids units were linear units and see what happens. It worked, but he realized that training the model took too many iterations, so the got discouraged and let the idea aside for a while.\n",
    "\n",
    "Backpropagation remained dormant for a couple of years until Hinton picked it up again. Rumelhart introduced the idea to Hinton, and Hinton thought it was a terrible idea. I could not work. He knew that backpropagation could not break the symmetry between weights and it will get stuck in local minima. He was passionate about energy-based systems known as [Boltzmann machines](https://www.cs.toronto.edu/~hinton/csc321/readings/boltz321.pdf), which seemed to have nicer mathematical properties. Yet, as he failed to solve more and more problems with Boltzmann machines, decided to try out backpropagation, mostly out of frustration. It worked amazingly well, way better than Boltzmann machines. He got in touch with Rumelhart about their results, and both decided to include a backpropagation chapter in the PDP book, and published *Nature* paper along with Ronald Williams. The *Nature* paper became highly visible and the interest in neural networks got reignited for at least the next decade. And that is how backpropagation was introduced: by a mathematical psychologist with no training in computational modeling and a neural net researcher that thought it was a terrible idea. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overcoming limitations and creating advantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truth be told, \"multilayer perceptron\" is a terrible name for what Rumelhart, Hinton, and Williams introduced in the mid-'80s. It is a bad name because its most fundamental piece, the *training algorithm*, is completely different from [the one in the perceptron](https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Learning-procedure). Therefore, a multilayer perceptron it is not simply \"a perceptron with multiple layers\", as the name suggests. True, it is a network composed of multiple neuron-like processing units, but not every neuron-like processing unit is a perceptron. If you were to put together a bunch of Rossenblat's perceptron in sequence, you would obtain something very different from what most people today would call a multilayer perceptron. If anything, the multi-layer perceptron is more similar to the Widrow and Hoff ADALINE, and in fact, Widrow and Hoff did try multi-layer ADALINEs, known as MADALINEs (i.e., many ADALINEs), but they did not incorporate non-linear functions.\n",
    "\n",
    "\n",
    "Now, the main reason for the resurgence of interest in neural networks was that finally, someone designed an architecture that could overcome the perceptron and ADALINE limitations: *to efficiently solve problems requiring non-linear solutions*. Problems like the famous [XOR (exclusive or)](https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Example-1:-the-XOR-problem) function (to learn more about it, see the \"Limitations\" section in the [\"The Perceptron\"](https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Example-1:-the-XOR-problem) and [\"The ADALINE\"](https://com-cog-book.github.io/com-cog-book/features/adaline.html#ADALINE-limitations) chapters). \n",
    "\n",
    "Further, a side effect of the capacity to use multiple layers of non-linear units, is that neural networks can form *complex internal representations of entities*. The perceptron and ADALINE did not have this capacity. They both are linear models, therefore, it doesn't matter how many layers of processing units you concatenate together, the representation learned by the network will be a linear model. You may as well have drop all the extra layers and the network eventually would learn the same solution with multiple layers (see [Why adding multiple layers of processing units does not work](https://com-cog-book.github.io/com-cog-book/features/perceptron.html#Why-adding-multiple-layers-of-processing-units-does-not-work) for an explanation). This capacity is important in so far complex multi-level representation of phenomena is -probably- what the human mind does when solving problems in language, perception, learning, etc. \n",
    "\n",
    "Finally, the backpropagation algorithm effectively automates the so-called \"feature engineering\" process. If you have ever done data analysis of any kind, you may have come across variables or features that were not in the original data, but that was *created by transforming or combining other variables*. For instance, you may have variables for income and education, and combine those to create a socio-economic status variable. That variable may have a predictive capacity above and beyond income and education in isolation. With a multi-layer neural network with non-linear units trained with backpropagation, such a *transformation process happens automatically* in the intermediate or \"hidden\" layers of the network. Those intermediate representations often are hard or impossible to interpret for humans. They may make no sense whatsoever for us, but somehow help to solve the pattern recognition problem at hand, so the network will learn that representation. Does this mean that neural nets learn different representations from the human brain? Maybe, maybe not. The problem is that we don't have direct access to the kind of representations learned by the brain either, and a neural net will seldom be trained with the same data that a human brain is trained in real life.\n",
    "\n",
    "The application of the backpropagation algorithm in multilayer neural network architectures was a major breakthrough in the artificial intelligence and cognitive science community, that catalyzed a new generation of research in cognitive science. Nonetheless, it took several decades of advance on computing and data availability before artificial neural networks became the dominant paradigm in the research landscape as it is today. Next, we will explore its mathematical formalization and application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical formalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classical multilayer perceptron as introduced by Rumelhart, Hinton, and Williams, can be described by:\n",
    "\n",
    "- a *linear function* that aggregates the input values\n",
    "- a *sigmoid function*, also called *activation function*\n",
    "- a *threshold function* for classification process, and an *identity function* for regression problems\n",
    "- a *loss or cost* function that computes the overall error of the network\n",
    "- a *learning procedure* to adjust the weights of the network, i.e., the so-called *backpropagation* algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear aggregation function is the same as in the perceptron and the ADALINE. But, there are two differences that will change the notation: now we are dealing multiple layers and processing units. The conventional way to represent this is with linear algebra notation. This is not a course of linear algebra, so I won't cover the mathematics in detail. Nonetheless, I'll introduce enough concepts and notation to understand the fundamental operations involved in the neural network calculation. The most important aspect is to understand what is a matrix, a vector, and how to multiple them together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector is a collection of ordered numbers, or *scalars*. If you are familiar with data analysis, a vector is a column or row in a dataframe. If you are familiar with programming, a vector is an array or a list. A generic Vector $\\bf{x}$ is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/vector.svg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix is a collection of vectors or lists of numbers. In data analysis this is equivalent to a 2 dimensional dataframe; in programming to a multidimensional array or a list of lists.A generic matrix $W$ is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/matrix.svg\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this notation, let's illustrate an example of a network with:\n",
    "- 3 inputs units\n",
    "- 1 hidden layer with 2 units\n",
    "\n",
    "Like the one in **Figure 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Figure 1</center>\n",
    "<img src=\"images/multi-perceptron/simple-net.svg\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input vector for our first training example would look like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\bf{x=}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 3 input units connecting to hidden 2 units we have 3x2 weights. This is represented with a matrix as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$W=\n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{12}\\\\\n",
    "w_{21} & w_{22}\\\\\n",
    "w_{31} & w_{32}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the linear function equals to the multiplication of the vector $\\bf{x}$ and the matrix $W$. In linear algebra, to perform the multiplication in this case we need to transpose the matrix $W$ to match the number of columns in $W$ with the number of rows in $\\bf{x}$. Transposing means to \"flip\" the columns of of $W$ such that the firts column becomes the first row, the second column the second row, and so forth. The matrix vector multiplication is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\bf z=} \n",
    "W^T\\times {\\bf x=}\n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{12} & w_{13} \\\\\n",
    "w_{21} & w_{22} & w_{23} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "x_1w_{11} + x_2w_{12} + x_3w_{13}\\\\\n",
    "x_1w_{21} + x_2w_{22} + x_3w_{23}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "z_1 \\\\\n",
    "z_2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous matrix operation in summation notation equal to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/linear-function-multi-perceptron.svg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, $f$ is a function of each element of the vector $\\bf{x}$ and each element of the matrix $W$. The $m$ index identifies the rows in $W^T$ and the rows in $\\bf{z}$. The $n$ index indicates the columns in $W^T$ and the rows in $\\bf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of the $z$ vector becomes an input for the sigmoid function $\\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/sigmoid-function-multi-perceptron.svg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of $\\sigma(z_m)$ is another $m$ dimensional vector $a$, one entry for each unit in the hidden layer like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\bf{a}=\n",
    "\\begin{bmatrix}\n",
    "a_1 \\\\\n",
    "a_2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, $a$ stands for \"activation\", which is a common way to refer to the output of hidden untis. This sigmoid function \"wrapping\" the outcome of the linear function is commonly refered as an \"activation function\". The idea is that a unit gets \"activated\" in more or less the same manner that a neuron gets activated when a sufficiently strong input is received. The selection of a sigmoid is arbitrary. There are multiple non-linear funcions that could be selected at this stage in the network. \n",
    "\n",
    "A nice property of sigmoid functions is they are \"mostly linear\", but they saturate as they approach to 1 and 0 in the extremes. **Chart 1** shows the shape of a sigmoid function (blue line), and the point where the gradient is at its maximun (red line connecting blue line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-ed19c55c3c654da993061be2399097b8\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-ed19c55c3c654da993061be2399097b8\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": \"line\", \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"z\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"a\"}}}, {\"mark\": {\"type\": \"rule\", \"color\": \"red\"}, \"encoding\": {\"x\": {\"type\": \"quantitative\", \"field\": \"z1\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"a1\"}}}], \"data\": {\"name\": \"data-4ce8df9580f59e633b8d399e9190ac6d\"}, \"title\": \"Chart 1\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-4ce8df9580f59e633b8d399e9190ac6d\": [{\"a\": 0.0066928509242848554, \"z\": -5.0, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.007391541344281971, \"z\": -4.9, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.00816257115315989, \"z\": -4.800000000000001, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.009013298652847815, \"z\": -4.700000000000001, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.009951801866904308, \"z\": -4.600000000000001, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.010986942630593162, \"z\": -4.500000000000002, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.012128434984274213, \"z\": -4.400000000000002, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.013386917827664744, \"z\": -4.3000000000000025, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.014774031693273017, \"z\": -4.200000000000003, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.01630249937144089, \"z\": -4.100000000000003, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.017986209962091496, \"z\": -4.0000000000000036, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.01984030573407743, \"z\": -3.900000000000004, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.021881270936130383, \"z\": -3.8000000000000043, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.024127021417669092, \"z\": -3.7000000000000046, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.026596993576865725, \"z\": -3.600000000000005, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.02931223075135617, \"z\": -3.5000000000000053, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.03229546469845033, \"z\": -3.4000000000000057, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.035571189272635965, \"z\": -3.300000000000006, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.03916572279676412, \"z\": -3.2000000000000064, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.043107254941085846, \"z\": -3.1000000000000068, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.04742587317756646, \"z\": -3.000000000000007, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.05215356307841737, \"z\": -2.9000000000000075, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.05732417589886832, \"z\": -2.800000000000008, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.06297335605699601, \"z\": -2.700000000000008, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.06913842034334627, \"z\": -2.6000000000000085, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.07585818002124294, \"z\": -2.500000000000009, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.08317269649392166, \"z\": -2.4000000000000092, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.09112296101485534, \"z\": -2.3000000000000096, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.09975048911968425, \"z\": -2.20000000000001, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.10909682119561194, \"z\": -2.1000000000000103, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.11920292202211644, \"z\": -2.0000000000000107, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.1301084743629966, \"z\": -1.900000000000011, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.1418510649004864, \"z\": -1.8000000000000114, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.15446526508353317, \"z\": -1.7000000000000117, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.16798161486607383, \"z\": -1.600000000000012, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.1824255238063545, \"z\": -1.5000000000000124, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.19781611144141623, \"z\": -1.4000000000000128, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.21416501695743917, \"z\": -1.3000000000000131, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.23147521650098, \"z\": -1.2000000000000135, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.24973989440487981, \"z\": -1.1000000000000139, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.26894142136999233, \"z\": -1.0000000000000142, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.28905049737499305, \"z\": -0.9000000000000146, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.3100255188723844, \"z\": -0.8000000000000149, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.3318122278318305, \"z\": -0.7000000000000153, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.35434369377420094, \"z\": -0.6000000000000156, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.3775406687981417, \"z\": -0.500000000000016, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.40131233988754406, \"z\": -0.40000000000001634, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.4255574831883369, \"z\": -0.3000000000000167, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.45016600268751783, \"z\": -0.20000000000001705, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.47502081252105566, \"z\": -0.10000000000001741, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.49999999999999556, \"z\": -1.7763568394002505e-14, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.5249791874789355, \"z\": 0.09999999999998188, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.5498339973124733, \"z\": 0.19999999999998153, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.5744425168116544, \"z\": 0.29999999999998117, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.5986876601124473, \"z\": 0.3999999999999808, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.62245933120185, \"z\": 0.49999999999998046, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.6456563062257908, \"z\": 0.5999999999999801, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.6681877721681616, \"z\": 0.6999999999999797, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.6899744811276081, \"z\": 0.7999999999999794, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.7109495026249997, \"z\": 0.899999999999979, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.7310585786300007, \"z\": 0.9999999999999787, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.7502601055951135, \"z\": 1.0999999999999783, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.7685247834990137, \"z\": 1.199999999999978, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.7858349830425548, \"z\": 1.2999999999999776, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8021838885585781, \"z\": 1.3999999999999773, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8175744761936402, \"z\": 1.499999999999977, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8320183851339212, \"z\": 1.5999999999999766, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8455347349164622, \"z\": 1.6999999999999762, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8581489350995093, \"z\": 1.7999999999999758, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8698915256369995, \"z\": 1.8999999999999755, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8807970779778798, \"z\": 1.9999999999999751, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.8909031788043846, \"z\": 2.0999999999999748, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9002495108803125, \"z\": 2.1999999999999744, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9088770389851418, \"z\": 2.299999999999974, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9168273035060757, \"z\": 2.3999999999999737, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9241418199787546, \"z\": 2.4999999999999734, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9308615796566515, \"z\": 2.599999999999973, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.937026643943002, \"z\": 2.6999999999999726, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9426758241011297, \"z\": 2.7999999999999723, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.947846436921581, \"z\": 2.899999999999972, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9525741268224319, \"z\": 2.9999999999999716, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9568927450589126, \"z\": 3.0999999999999712, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9608342772032344, \"z\": 3.199999999999971, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9644288107273629, \"z\": 3.2999999999999705, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9677045353015485, \"z\": 3.39999999999997, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9706877692486428, \"z\": 3.49999999999997, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9734030064231335, \"z\": 3.5999999999999694, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.97587297858233, \"z\": 3.699999999999969, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9781187290638689, \"z\": 3.7999999999999687, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9801596942659219, \"z\": 3.8999999999999684, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.982013790037908, \"z\": 3.999999999999968, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9836975006285584, \"z\": 4.099999999999968, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9852259683067265, \"z\": 4.199999999999967, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9866130821723347, \"z\": 4.299999999999967, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9878715650157253, \"z\": 4.399999999999967, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9890130573694065, \"z\": 4.499999999999966, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9900481981330953, \"z\": 4.599999999999966, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9909867013471519, \"z\": 4.6999999999999655, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9918374288468399, \"z\": 4.799999999999965, \"z1\": 0, \"a1\": 0.5}, {\"a\": 0.9926084586557179, \"z\": 4.899999999999965, \"z1\": 0, \"a1\": 0.5}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "z = np.arange(-5.0,5.0, 0.1)\n",
    "a = expit(z)\n",
    "df = pd.DataFrame({\"a\":a, \"z\":z})\n",
    "df[\"z1\"] = 0\n",
    "df[\"a1\"] = 0.5\n",
    "sigmoid = alt.Chart(df).mark_line().encode(x=\"z\", y=\"a\")\n",
    "threshold = alt.Chart(df).mark_rule(color=\"red\").encode(x=\"z1\", y=\"a1\")\n",
    "(sigmoid + threshold).properties(title='Chart 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification problems, each output unit uses a threshold function as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y} =\n",
    "f(a_m)\n",
    "\\begin{cases}\n",
    "+1, & \\text{if } a \\text{ > 0.5} \\\\\n",
    "-1, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regression problems, this is, problems that require a real-valued output value, like predicting income or test-scores, each output unit uses an identity function as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{y}=f(a_m)=a_m\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple terms, an identity function returns the same value as the input. It does nothing. The point is that the $a$ is already the output of a linear function, therefore, is the value that we need for this kind of problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function is the measure of \"goodness\" or \"badness\" (depending on how you like to see things) of the network. This can be a confusing term. People sometines call it *objective function* or *loss function* as well. Conventionally, *loss function* usually refers to the measure of error for a *single* training case, *cost function* to the aggregate error for the *entire* dataset, and *objective function* is a more generic term refering to any measure of overall error in a network. For instance, \"mean squared error\", \"sum of squared error\", and \"binary cross entropy\" are all *objective functions*.\n",
    "\n",
    "Nowadays, you would probably want to use different cost functions for different types of problems. In their original work, Rumelhart, Hinton, and Williams used the sum of equared errors, defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/cost-function.svg\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward propagation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All neural networks can be divided in two parts: a *forward propagation phase*, where the information \"flows\" forward to compute predictions and the error; and the *backward propagation phase*, where the *backpropagation algorithm* computes the error derivatives and update the network weights. **Figure 2** illustrate a network with 2 input units, 3 hidden units, and 1 output unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 2 </center>\n",
    "<img src=\"images/multi-perceptron/forward-pass.svg\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *forward propagation* phase involves \"chaining\" all the steps we defined so far: the *linear function*, the *sigmoid function*, and the *threshold function*. Consider the network in **Figure 2**. Let's name the linear function as $\\lambda()$, the sigmoid function as $\\sigma()$, and the threshold function as $\\tau()$. Now, the network in **Figure X** can be represented as:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\tau(\\sigma^{(2)}(\\lambda^{(2)}(\\sigma^{(1)}(\\lambda^{(1)}(x_n, w_{mn})))))\n",
    "$$\n",
    "\n",
    "All neural networks can be represented as a composition of functions, where each step is nested in the next step. For instance, we can add an extra hidden layer to the network in **Figure 2** by:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\tau(\\sigma^{(3)}(\\lambda^{(3)}(\\sigma^{(2)}(\\lambda^{(2)}(\\sigma^{(1)}(\\lambda^{(1)}(x_n, w_{mn})))))))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [ADALINE chapter](https://com-cog-book.github.io/com-cog-book/features/adaline.html#The-ADALINE-error-surface) I introduced the ideas of searching for a set of weights that minimize the error via gradient descent, and the difference between convex and non-convex optimization. If you have not read that section, I'll encourage you to read that first. Otherwise, the important part is to remember that since we are introducing non-linearities in the network the error surface of the multilayer perceptron is [non-convex](https://arxiv.org/pdf/1712.07897.pdf). This means that there are multiple \"valleys\" with \"local minima\", along with the \"global minima\", and that backpropagation **is not garanteed to find the global minima**. Remember that the \"global minima\" is the point where the error (i.e., the value of the cost function) is at its minimun, whereas the \"local minima\" is the point of minimun error for a sub-section of the error surface. **Figure 3** illustrate these concepts in a 3D surface. The vertical axis represent the error of the surface, and the other two axes represent different combinations of weights for the network. In the figure you can observe how different combinations of weights produce different values of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 3 </center>\n",
    "<img src=\"images/multi-perceptron/sse-nonconvex.svg\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the ingredients to introduce the almighty backpropagation algorithm.\n",
    "\n",
    "Remember that our goal is to learn **how the error changes as we change the weights of the network by tiny amount**, and that the cost function was defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E = \\frac{1}{2}\\sum_k(a_k - y_k)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one piece of notation I'll introduce to clarify where in the network are we at each step of the computation. I'll use the superscript $L$ to index the outermost function in the network. For example, $a^{(L)}$ index the last sigmoid activation function at the output layer, whereas $a^{(L-1)}$ indicates the previous sigmoid activation function at the hidden layer. Think on this as moving from right $(L)$ to left $(L-1)$ in the computational graph of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation for single unit multi-layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my experience, tracing the indices in backpropagation is the most confusing part, so I'll ignore the summation symbol and drop the subscript $k$ to make the math as clear as possible. You can think of this as having a network with a single input unit, a single hidden unit, and a single output unit, as in **Figure 4**. We will first work out backpropagation for this simplified network, and then expand for the multi-neuron case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 4 </center>\n",
    "<img src=\"images/multi-perceptron/single-unit.svg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If backpropagation were an oracle, this is what we would want to ask: **\"How does the error change when we change the weights by a tiny amount?\"**\n",
    "\n",
    "The backpropagation would reply: \n",
    "\n",
    ">You have to realize the following:  \n",
    "*The error, $E$, depends on the value of the sigmoid activation function, $a$.*  \n",
    "*The value of the sigmoid function activation function, $a$, depends on the value of the linear function, $z$.*  \n",
    "*The value of the linear function, $z$, depends on the value of the weights, $w$*  \n",
    "\n",
    ">Therefore, what you have to figure out is:\n",
    "\n",
    ">*How does the error change when we change the activation $a$ by a tiny amount*  \n",
    "*How does the activation $a$ change when we change the activation $z$ by a tiny amount*  \n",
    "*How does $z$ change when we change the weights $w$ by a tiny amount*  \n",
    "\n",
    "Therefore, we have to **answer those three questions in a sequence**. Mathematically, it can be expressed with the chain-rule of calculus as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/multi-perceptron/chain-rule.svg\"  width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No deep knowledge of calculus is needed to understand what the chain-rule is doing. In essense, indicates how to differentiate [composite functions](https://en.wikipedia.org/wiki/Function_composition), or functions nested inside other functions. If you remember the section above this one, we showed that a multi-layer perceptron can be expressed as a composite function. Very convinient. The rule says that we take the derivative of the outermost function, and multiple by the derivative of the inside function, recursively. That's it.\n",
    "\n",
    "Good. Now, we have to differentiate each of those expression and replace to obtain the final expression.\n",
    "\n",
    "Let's begin from the outermost part, the error with respect to the sigmoid activation function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial a^{(L)}} = a^{(L)} - y \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the sigmoid activation function with respect to the linear function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial a^{(L)}}{\\partial z^{(L)}} = a(1-a) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the linear function with respect to the weights:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial z^{(L)}}{\\partial w^{(L)}} = a^{(L-1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the pieces to replace and get our expression as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L)}}  = a^{(L)} - y \\times a(1-a) \\times a^{(L-1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have figured out how the error changes as we change the weight connecting the **hidden layer and the output layer $w^{(L)}$**. Amazing progress. We still need to know how the error changes as we adjust the weight connecting the **input layer and the hidden layer $w^{(L-1)}$**. Fortunately, this is pretty straighforward: we apply the chain-rule again, and again, until we get there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E}{\\partial w^{(L-1)}} = \\frac{\\partial E}{\\partial a^{(L)}} \\times \\frac{\\partial a^{(L)}}{\\partial z^{(L)}} \\times \\frac{\\partial z^{(L)}}{\\partial w^{(L)}} \\times \\frac{\\partial w^{(L)}}{\\partial a^{(L-1)}} \\times \\frac{\\partial a^{(L-1)}}{\\partial z^{(L-1)}}  \\times \\frac{\\partial z^{(L-1)}}{\\partial w^{(L-1)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation for multiple unit multi-layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty much all neural networks you'll find have more than one neuron. Until now, we have been assuming a network with a single neuron per layer. The only difference between the expressions we have used so far and adding more units, is an extra index. For example, we can use the letter $k$ to index the units in the hidden layer and the letter $j$ to index the units in the output layer. We also need indices for the weights. For any network with multiple units, we will have more weights than units, which means we will need two subscripts to indicate each weight. This is visible in the weight matrix in **Figure 2**. We can use the same indices $j$ and $k$ to index the weights. With all this, our original equation for the derivative of the error with respect to the weights in $(L)$ becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E_i}{\\partial w^{(L)}_{jk}} = \\frac{\\partial E_i}{\\partial a^{(L)}_j} \\times \\frac{\\partial a^{(L)}_j}{\\partial z^{(L)}_j} \\times \\frac{\\partial z^{(L)}_j}{\\partial w^{(L)}_{jk}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that I'll aso added a $i$ subscript to $E$. This is to reflect the fact that now we want to compute the error derivative for all training examples instead of one. \n",
    "\n",
    "There is a second important thing to consider. This time we have to take into account that each sigmoid activation $a$ from  $(L-1)$ layers impacts the error via multiple pathways. In **Figure 5** this is illustrated by blue and red connections to the output layer. To reflect this, we add a summation symbol and the expression for the derivative of the error with respet to the sigmoid activation becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E_i}{\\partial a^{(L-1)}_k} = \\sum_{j} \\frac{\\partial E_i}{\\partial a^{(L)}_j} \\times \\frac{\\partial a^{(L)}_j}{\\partial z^{(L)}_j} \\times \\frac{\\partial z^{(L)}_j}{\\partial a^{(L-1)}_k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, considering both the new subscripts and the derivation for $\\frac{\\partial E_i}{\\partial a^{(L-1)}_k}$, we can apply the chain-rule one more time to compute the error derivatives for the weights in the $(L-1)$ layer as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial E_i}{\\partial w^{(L-1)}_{jk}} = \\left(\\sum_{j} \\frac{\\partial E_i}{\\partial a^{(L)}_j} \\times \\frac{\\partial a^{(L)}_j}{\\partial z^{(L)}_j} \\times \\frac{\\partial z^{(L)}_j}{\\partial a^{(L-1)}_k}\\right)  \\times \\frac{\\partial a^{(L-1)}_k}{\\partial z^{(L-1)}_k} \\times \\frac{\\partial z^{(L-1)}_k}{\\partial w^{(L-1)}_k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. Those are all the pieces for th backpropagation algorithm. As you may have notice, the hardest part is to track all the indices. To further clarify the notation, you can look at the diagram in **Figure 5** that exemplify where each piece of the equation is located."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> Figure 5 </center>\n",
    "<img src=\"images/multi-perceptron/backprop.svg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation weight update "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one piece we are missing still: how to update the weights for each layer. Since we learned how to compute the gradients, this process is way more straighforward. We just need to change each weight by a portion of its negative gradient as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "w_{jk}^{L} = w_{jk}^{L} - \\eta \\times \\frac{\\partial E}{\\partial w_{jk}^{L}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $\\eta$ is the *step size* or *learning rate*. If you are not familiar witht the idea a learning rate, you can review the ADALINE Chapter where I briefly explain the concept [here](https://com-cog-book.github.io/com-cog-book/features/adaline.html#Learning-procedure). In brief, a learning rate controls how fast we descend over the error surface given the computed gradient. This is important because we want to given steps just large enough to reach the minima of the surface, at any point we may be for searching for the weights. A more in deep explanation [here](https://en.wikipedia.org/wiki/Learning_rate).\n",
    "\n",
    "I don't know about you but I have to go over several rounds of carefully studying the equations behind backpropagation to finally understand them fully. This may or not be true for you, but in generall I'll say that the effort pays off as **backpropagation is the engine of every neural network model today**. Regardless, the good news are the modern numerical computation libraries like `numpy`, `Tensorflow`, `Zarr`, and `pytorch` provide all the necessary methods and abstractions to make the implementation of neural networks and backpropagation easy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer perceptron implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kelley, H. J. (1960). Gradient theory of optimal flight paths. Ars Journal, 30(10), 947–954.\n",
    "\n",
    "Bryson, A. E. (1961). A gradient method for optimizing multi-stage allocation processes. Proc. Harvard Univ. Symposium on Digital Computers and Their Applications, 72.\n",
    "\n",
    "\n",
    "Werbos, P. J. (1994). The roots of backpropagation: From ordered derivatives to neural networks and political forecasting (Vol. 1). John Wiley & Sons.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
